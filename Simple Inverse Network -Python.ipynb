{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from numpy.linalg import inv\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import seed\n",
    "from random import random\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "w1 = np.random.rand()\n",
    "w3 = np.random.rand()\n",
    "w2 = np.random.rand()\n",
    "w4 = np.random.rand()\n",
    "\n",
    "print(np.array([[w1,w2],[w3,w4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This funtion generates data \n",
    "np.random.seed(42)\n",
    "def data_generator(n):\n",
    "    np.random.seed(42)\n",
    "    As = []    \n",
    "    x = np.random.normal(0,1,size = (2,n)) # n is the size of sample\n",
    "    noise = np.random.normal(0,0.04**2) \n",
    "    \n",
    "    for condition_number in [1,0.1,0.01,0.0001]: # create a list of As with different conditional number\n",
    "        A = np.matrix([[1, 1], [1, 1+condition_number]])\n",
    "        As.append(A)\n",
    "        \n",
    "    y1 = np.dot(As[0],x) + 0.01*noise #compute y with different A\n",
    "    y01 = np.dot(As[1],x) + 0.01*noise\n",
    "    y001 = np.dot(As[2],x) + 0.01*noise\n",
    "    y0001 = np.dot(As[3],x) + 0.01*noise\n",
    "    \n",
    "    x = torch.Tensor(x).float() #convert all ndarrays to tensors\n",
    "    y1 = torch.Tensor(y1).float()\n",
    "    y01 = torch.Tensor(y01).float()\n",
    "    y001 = torch.Tensor(y001).float()\n",
    "    y0001 = torch.Tensor(y0001).float()\n",
    "#     print(x.size())\n",
    "#     print(y1.size())\n",
    "    \n",
    "    return x, y1, y01, y001, y0001    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Relu(Z):\n",
    "    return np.maximum(0,Z)\n",
    "\n",
    "def dRelu(x):\n",
    "    return np.where(x > 0, 1.0, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class net:\n",
    "    def __init__(self, x, y):\n",
    "        self.X=x\n",
    "        self.Y=y\n",
    "        self.Yh=np.zeros((1,self.Y.shape[1]))\n",
    "        self.L=2\n",
    "        self.dims = [2, 4, 2]\n",
    "        self.weights = {}\n",
    "        self.ch = {} # a cache variable\n",
    "        self.loss = []\n",
    "        self.lr=0.03\n",
    "        self.size = self.Y.shape[1]\n",
    "    def nInit(self):    \n",
    "        np.random.seed(1)\n",
    "        self.weights['W'] = np.array([[w1,w2],[w3,w4]]) \n",
    "        return\n",
    "\n",
    "    def forward(self):    \n",
    "        Z1 = self.weights['W'].dot(self.X)\n",
    "        self.Yh=Z1\n",
    "        loss=self.calculate_loss(Z1)\n",
    "        return self.Yh, loss\n",
    "    \n",
    "    def calculate_loss(self,Yh):\n",
    "        loss = (torch.norm(self.Y-torch.from_numpy(Yh)))**2 * (1./self.size) #norm\n",
    "        return loss\n",
    "    \n",
    "    def backward(self):\n",
    "\n",
    "        dLoss_Yh = -2*(self.Y - torch.from_numpy(self.Yh))* (1./self.size)\n",
    "        dLoss_W = np.dot(dLoss_Yh,self.X.T) \n",
    "\n",
    "        self.weights[\"W\"] = self.weights[\"W\"] - self.lr * dLoss_W\n",
    "\n",
    "\n",
    "    def run(self,X, Y, epochs):\n",
    "        self.loss = []\n",
    "        np.random.seed(42)                         \n",
    "        self.nInit()\n",
    "        for i in range(0, epochs):\n",
    "            Yh, loss=self.forward()\n",
    "            self.backward()\n",
    "            if i % 1 == 0:\n",
    "#                 print (\"Cost after iteration %i: %f\",(i, loss))\n",
    "                self.loss.append(loss)\n",
    "        print(\"-\"*50)\n",
    "        print(\"W\",self.weights[\"W\"],\"\\n\")\n",
    "#         print(\"Y\",Y)\n",
    "#         print(\"Yh\",Yh)\n",
    "        return self.loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_main(n,epochs):\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    train_x_all, train_y_1,train_y_01,train_y_001,train_y_0001= data_generator(n) # create the data \n",
    "    \n",
    "    nn = net(train_y_1, train_x_all)\n",
    "    list_1 = nn.run(train_y_1, train_x_all,epochs)\n",
    "    nn = net(train_y_01, train_x_all)\n",
    "    list_01 = nn.run(train_y_01, train_x_all,epochs)\n",
    "    nn = net(train_y_001, train_x_all)\n",
    "    list_001 = nn.run(train_y_001, train_x_all,epochs)\n",
    "    nn = net(train_y_0001, train_x_all)\n",
    "    list_0001 = nn.run(train_y_0001, train_x_all,epochs)     \n",
    "    \n",
    "    # plot 3000 epochs and the losses\n",
    "    epochs = 3000\n",
    "    plt.suptitle('Simple Inverse_net - python')\n",
    "    plt.plot(range(epochs),list_1)\n",
    "    plt.plot(range(epochs),list_01)\n",
    "    plt.plot(range(epochs),list_001)\n",
    "    plt.plot(range(epochs),list_0001)\n",
    "    x1,x2,y1,y2 = plt.axis()\n",
    "    plt.axis((x1,x2,0,14))\n",
    "    plt.xlabel('Normalised Number of Epochs')\n",
    "    plt.ylabel('Mean Squared Error')\n",
    "    plt.legend(['1', '0.1', '0.01', '0.0001'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_main(10000,3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tick_inverse_main(n,epochs):\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    train_x_all, train_y_1,train_y_01,train_y_001,train_y_0001= data_generator(n) # create the data \n",
    "    \n",
    "    for index,Y in enumerate([train_y_1,train_y_01,train_y_001,train_y_0001]):\n",
    "        globals()['x_tik_'+str(index)] = np.matmul(np.matmul(inv(np.matmul(As[index].T,As[index])\n",
    "                                                                 +0.04**2*np.eye(2)),As[index].T),Y)\n",
    "    \n",
    "    nn = net(train_y_1,x_tik_0)\n",
    "    list_1 = nn.run(train_y_1,x_tik_0,epochs)\n",
    "    \n",
    "    nn = net(train_y_01, x_tik_1)\n",
    "    list_01 = nn.run(train_y_01, x_tik_1,epochs)\n",
    "    \n",
    "    nn = net(train_y_001, x_tik_2)\n",
    "    list_001 = nn.run(train_y_001, x_tik_2,epochs)\n",
    "    #print(list_001)\n",
    "    \n",
    "    nn = net(train_y_0001, x_tik_3)\n",
    "    list_0001 = nn.run(train_y_0001, x_tik_3,epochs)  \n",
    "\n",
    "    # plot 3000 epochs and the losses\n",
    "    epochs = 3000\n",
    "    plt.suptitle('Inverse Problem(tikhonov) -simple network - python')\n",
    "    plt.plot(range(epochs),list_1)\n",
    "    plt.plot(range(epochs),list_01)\n",
    "    plt.plot(range(epochs),list_001)\n",
    "    plt.plot(range(epochs),list_0001)\n",
    "    x1,x2,y1,y2 = plt.axis()\n",
    "    plt.axis((x1,x2,0,14))\n",
    "    plt.xlabel('Number of Epochs')\n",
    "    plt.ylabel('Normalised Mean Squared Error')\n",
    "    plt.legend(['1', '0.1', '0.01', '0.0001'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "As = []\n",
    "for condition_number in [1,0.1,0.01,0.0001]: # create a list of As with different conditional number\n",
    "        A = np.matrix([[1, 1], [1, 1+condition_number]]) \n",
    "        As.append(A)\n",
    "        \n",
    "for index,A in enumerate(As):\n",
    "        globals()['tick_approx_'+str(index)] = np.matmul(inv(np.matmul(As[index].T,As[index])+0.04**2*np.eye(2)),As[index].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tick_approx_1\",tick_approx_0,\"\\n\")\n",
    "print(\"tick_approx_0.1\",tick_approx_1,\"\\n\")\n",
    "print(\"tick_approx_0.01\",tick_approx_2,\"\\n\")\n",
    "print(\"tick_approx_0.0001\",tick_approx_3,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick_inverse_main(10000,3000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
